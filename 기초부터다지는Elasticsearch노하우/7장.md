# 7장. 클러스터 성능 모니터링과 최적화
사용 중인 클러스터의 자원 상황은 어떠한지 요청을 얼마나 빠르게 얼마나 많이 처리하고 있는지 지표를 수집하고 모니터링 하는 것은 중요한 업무이다.


## 클러스터 상태 확인하기
```shell
curl -s http://localhost:9200/_cat/health?v&format=json&pretty
```
위 명령을 통해 아래 정보들을 얻을 수 있다
- 클러스터 상태 (green, yellow, red)
    - green : 모든 샤드가 정상적인 상태
    - yellow : 프라이머리 샤드는 정상, 일부 혹은 레플리카 샤드가 비정상적
    - red : 프라이머리 샤드 및 레플리카 샤드가 비 정상적 ( 데이터 유실의 가능성이 있음)
- 클러스터를 구성하고 있는 전체 노드 수
- 노드 중 데이터 노드 수
- 전체 샤드 수
- 샤드 중 프라이머리 샤드 수
- 클러스터에서 재배치되고 있는 샤드의 개수
- 클러스터에서 초기화되고 있는 샤드의 수
- unassinged 샤드 수
- 실행되지 못하고 큐에 쌓여있는 작업 수
- 작업이 실행되기까지 소요된 최대 시간
- 정상적으로 동작하는 샤드의 비율

## 노드 상태 확인하기
```shell
curl -s http://localhost:9200/_cat/nodes?v
```
위 명령을 통해 아래 정보들을 얻을 수 있다
- 노드의 IP 주소
- 힙 메모리 사용률
    - 이 값이 크면 클수록 사용 중인 힙 메모리의 양이 많다는 뜻
    - 일정 수준 이상 커지면 old GC에 의해 힙 메모리 사용률이 다시 내려간다
    - 만약 이 값이 낮아지지 않고 85% 이상을 계속 유지한다면 OOM 을 발생할 가능성이 크기 때문에 분석이 필요함
- 메모리 사용률
    - heap.percent : JVM 메모리 중 사용률
    - ram.percent : OS 전체 메모리 중 사용률, 대부분 90 퍼 이상의 높은 값을 나타내는데, JVM에 할당된 힙 메모리 외의 영역은 OS 에서 I/O 부하를 줄이기 위해 페이지 캐시로 사용하고 있기 때문
- 노드의 CPU 사용률
- 1,5,15 분 평균 load average 
- 노드의 역할 d : 데이터 노드, i : 인제스트 노드, m : 마스터 노드
- 마스터 역할 노드
- 노드 이름

### help 옵션
기본으로 제공되는 정보 외에 어떤 정보를 볼 수 있는지 확인할 수 있음
모든 api 에서 사용 가능

```shell
curl -s http://localhost:9200/_cat/nodes?help 
```
```shell
curl -s http://localhost:9200/_cat/nodes?v&h=node.id,name,disk.used_percent
```

## 인덱스의 상태와 정보 확인
```shell
curl -s http://localhost:9200/_cat/indices
```
위 명령을 통해 아래 정보들을 얻을 수 있다
- 인덱스의 상태값 green, yellow, red
    - 여기서 하나라도 yellow 면 클러스터의 상태도 yellow, red라면 클러스터의 상태도 red
- 인덱스 사용 여부 open/close
- 인덱스의 이름
- 인덱스의 uuid
- 인덱스 구성하는 프라이머리 샤드 개수
- 인덱스의 replication 값
- 저장 문서 개ㅅ
- 삭제 문서 개수
- 인덱스 전체 용량
- 인덱스 프라이머리 샤드 용량


### 인덱스 필드 데이터 캐시 크기 확인하기
```shell
curl -s "http://localhost:9200/_cat/indices?v&h=index,fielddata.memory_size"
```

## 클러스터 상태가 red 일 때 분석 방법
1. 클러스터의 상태를 확인한다.
    - _cat/health
2. 어떤 인덱스에서 red 상태인지 확인한다.
    - _cat/indices
3. 인덱스의 어떤 샤드가 문제인지 확인한다.
    - _cat/shards

red 상태를 제외하고 검색의 유실이 발생하진 않는다.
만약 red 상태의 인덱스가 이미 인덱싱이 끝난 과거 로그들이라면 해당 인덱스의 샤드가 저장되어 있는 데이터 노드의 복구를 통해 유실 없이 장애가 종료될 수 있음

## 샤드 상태 확인하기
```shell
curl -s "http://localhost:9200/_cat/shards?v"
```
이 API 는 클러스터의 상태가 RED 일 때 더 유용하다. 어떤 인덱스가 red인지 알아내고 어느 정도의 비율로 문서 유실이 일어나는지 알 수 있음
n개의 프라이머리 샤드 중 어떤 샤드가 배치되지 않았는지 확인 가능

위 명령을 통해 아래 정보들을 얻을 수 있다
- 인덱스의 이름
- 인덱스의 샤드 번호
- 프라이머리 샤드인지 레플리카 샤드인지 p,r
- 샤드의 상태
- 샤드에 저장된 문서의 수
    - 대부분 샤드별로 수치가 비슷하지만 라우팅을 사용하는 문서의 수가 다를 수 있음
- 샤드의 크기
- 샤드가 배치된 데이터 노드의 ip
- 샤드가 배치된 데이터 노드 이름

 * 샤드의 상태
| 값 | 의미 | 
| ------ | ------ |
| STARTED | 정상 |
| INITIALIZING| 샤드 초기화하는 상태, 최초 배치 혹은 샤드에 문제가 발생하여 새롭게 배치할 시의 상태 |
| RELOCATING | 샤드가 현재 노드에서 다른 노드로 이동하고 있는 상태, 새로운 데이터가 추가되고나 기존 데이터 노드에 문제가 생겨서 샤드가 새로운 노드에 배치되어야 할 때의 상태|
| UNASSIGNED | 어느 노드에도 배치되지 않은 상태, 해당 샤드에 문제가 생기거나 클러스터의 라우팅 정책에 의해 배치되지 않은 상태|

### unassigned 원인 확인하기
```shell
curl -s "http://localhost:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason"
```
- INDEX_CREATED : 인덱스 생성 후 샤드가 배치되지 않았음
- NODE_LEFT : 샤드가 배치된 데이터 노드의 문제생겨 클러스터에서 제외될 경우


## Stats API로 지표 확인

### 클러스터의 성능 지표
```shell
curl -s "http://localhost:9200/_cluster/stats"
```
- 클러스터에 색인된 전체 문서 개수
- 클러스터 전체 삭제 문서 개수
- 저장중인 데이터 크기 
- 필드 데이터 캐시의 크기
    - 문자열 필드에 대한 통계 작업을 할 때 필요한 데이터
    - 필드 데이터 양이 많으면 힙 메모리 공간을 많이 사용하기 때문에 모니터링 필요
    - 노드의 힙 메모리 사용률 높다면 우선적으로 확인해야 함
- 쿼리 캐시 크기
- 세그먼트 개수
- 노드 버전
- JVM 버전 및 GC


### 노드의 성능 지표
```shell
curl -s "http://localhost:9200/_nodes/stats"
```
- "indexing"."index_total"
    - 지금까지 노드가 색인한 문서의 수, 카운터 형식의 값으로 0부터 계속해서 값이 증가함, 즉 지금 호출한 값과 1분 후 호출한 값이 차이가 나며 이 값의 차이가 1분동안 색인된 문서의 개수를 나타냄
    - 이 값을 통해 색인 속도를 알 수 있음
- "indexing"."index_time_in_mills"
    - 색인에 소요된 시간
- "get"
    - GET 요청으로 문서를 가져오는 성능
    - 클러스터의 성능을 나타내는 중요 지표
    - 단일 도큐먼트에 대한 검색
- "search"
    - 검색 성능 관련 지표 
- get, search 차이 : get은 ID 를 통해 get 하는 검색 통계
- merges
    - 세그먼트 병합 관련 성능 지표
    - 역시 카운터 형식의 지표 세그먼트를 얼ㄹ마나 병합했는지 병합할 때 어느 정도의 시간이 소요되었는지
- query_cache
    - 쿼리 캐시 관련 지표
    - 현재 노드에서 사용 중인 쿼리 캐시의 정도
    - 클러스터에서 확인한 값과 다르게 노드별로 사용 중인 값을 보여줌
- fielddata
    - 필드 데이터 캐시
    - 현재 노드에서 사용 중인 필드 데이터의 크기
- cpu
    - 노드의 cpu 사용률
    - load_average : 각각 1분, 5분, 15분 평균
- gc.collectors
    - GC 관련 성능 지표
- thread_pool
    - 노드의 쓰레드풀 상태
    - rejected 지표가 중요
    - 현재 노드가 처리할 수 있는 양보다 많은 요청이 들어오고 있기 때문에 더 이상 처리할 수 없어서 처리를 거절한다는 의미

## 성능 확인과 문제 해결
클러스터 전체 성능과 각 노드의 개별 성능으로 나눠 적용할 수 있음
이렇게 나누는 이유는 색인이나 검색이 특정 노드로 몰릴 수 있기 때문
색인과 검색이 클러스터 내의 데이터 노드들 사이에 큰 차이 없이 가능한 한 균일하게 나뉘어야 클러스터가 최적의 성능을 낼 수 있음
1. 색인 성능
    - 초당 몇 개의 문서를 색인할 수 있는지 그리고 각 문서를 색인하는 데 소요되는 시간이 어느 정도인지를 나타냄
2. 검색 성능
    - 초당 몇 개의 쿼리를 처리할 수 있는지 그리고 각 쿼리를 처리하는 데 소요되는 시간이 어느 정도인지
3. GC 성능
    - GC 가 너무 자주, 오래 발생하면 Stop-the-world 같은 응답 불가 현상이 발생한다. Stop-the-world 가 얼마나 자주 오래 발생하는지를 나타낸다
4. rejected 
    - 클러스터가 처리하라 수 없는 수준의 요청이 들어오면 클러스터는 요청을 거절하게 되는데 그 횟수


### 색인 성능 살펴보기
#### 클러스터의 색인 성능 확인
```shell
curl -s "http://localhost:9200/stats"
```
- 프라이머리 샤드에 대한 색인 성능과 전체 샤드에 대한 색인 성능으로 나뉨
- 10초 동안 호출한 색인 수와 색인된 시간을 확인할 수 있음
- 하나의 문서를 색인하는 데에 얼마나 소요되는지를 확인해야 함 (reindex 시 확인)

#### 검색 성능 확인
```shell
curl -s "http://localhost:9200/stats"
```
"search_total","fetch_total"
1. query : 검색 요청을 받은 노드는 해당 쿼리를 다른 노드에도 전달한다. 그럼 각각의 노드는 자신이 가지고 있는 샤드 내에서 검색 쿼리에 해당하는 문서가 있는지 찾는 과정을 진행한다. 이 과정이 쿼리
2. fetch : 이렇게 찾은 문서들을 리스트의 형태로 만들어서 정리하는 과정
검색 응답은 query와 fetch의 과정이 모두 끝나야 만들어지기 때문에 성능 측정 시 모두 포함해야 함


초당 몇 개의 query와 fetch 가 발생하는지 그리고 각각에 소요되는 시간은 어느 정도인지 알 수 있다.
> query_then_fetch VS dfs_query_then_fetch
> query_then_fetch : 각 샤드에 쿼리 전송 -> local tf/idf 를 계산 -> 이후 작업
> dfs_query_then_fetch : 각 샤드에 tf/idf 쿼리 수행 -> 각 샤드에 쿼리 전송 -> grobal tf/idf 를 계산 -> 이후작업 (dfs : documnet frequency statics)
> 차이점 : tf/idf 를 수행하는 대상이 각 노드 단위인지, 전체 노드인지의 차이인 것 같다

#### GC 성능 확인하기
```shell
curl -s "http://localhost:9200/_nodes/stats"
```
- GC 각 노드에서 발생하기 때문에 nodes API를 이용하여 성능 지표를 볼 수 있음
- 특정 시간 동안 발생한 GC 의 횟수와 시간을 통해 성능 확인
- 운영하는 환경마다 다르겠지만 수십에서 수백 ms 정도의 성능을 내는 것이 안정적이다.
- young.collection_count
- young.collection_time_in_mills
- old.collection_count
- old.collection_time_in_mills

ES 에 영향을 미치는 부분
1. 긴 GC 수행 시간에 따른 Stop-The-World gustkd
2. Out of Memory 에러

#### rejected 
```shell
curl -s "http://localhost:9200/_nodes/stats"
```
- 클러스터 레벨에서 현재 처리량이 부족하다는 것을 알 수 있는 지표 중 하나
- ES 는 현재 처리할 수 있는 양보다 많은 양의 요청이 들어올 경우 큐에 요청을 쌓아둠
- 큐도 꽉차게 되면 rejected 에러가 발생함
- 즉 이 수치가 높아진다면 현재 클러스터의 처리량이 부족하다는 것
- rejected 는 각 스레드별로 확인 가능
- write 스레드에서 발생하면 색인 성능이 부족하다는 것
- search 스레드에서 발생하면 검색 성능이 부족하다는 것
- 해결 방법  : 큐를 늘림, 평상시에는 처리량이 부족하지 않기 때문에 큐를 늘리는 방식으로 대응하면 순간적으로 요청이 몰렸을 때 rejected 를 발생시키지 않고 큐에 담았다가 순차적으로 실행시킬 수 있음
```shell
thread_pool.write.queue_size: 10000
thread.pool.search.max_queue_size: 10000
```

