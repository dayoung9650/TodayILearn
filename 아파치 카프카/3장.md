# 카프카 기본 개념
## 카프카 브로커
- 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 데이터를 분산저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션
- 1 서버 = 1 브로커


## 데이터 저장 및 전송
- 프로듀서에서 데이터를 전달받으면 프로듀서가 요청한 토픽의 파티션에 데이터를 저장하고 컨슈머가 데이터를 요청하면 파티션에 저장된 데이터를 저정한다.
- 프로듀셔로부터 전달된 데이터는 파일 시스템에 저장된다
- 하나의 파티션에 하나의 디렉토리
- 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장함

> 카프카가 파일시스템에 데이터를 저장(파일 입출력)하지만 느리지 않은 이유 ? 
> 페이지 캐시를 사용하여 디스크 입출력 속도를 높임
> 페이지 캐시 = OS 에서 파일 입출력의 성능 향상을 위해 만들어 놓은 메모리 영역
> 한 번 익은 파일의 내용은 메모리의 페이지 캐시 영역에 저장함 추후 동일한 파일의 접근이 일어나면 디스크에서 읽지 않고 메모리에서 직접 읽음
> 카프카 브로커를 실행하는데 힙 메모리 사이즈를 크게 설정할 필요가 없음

> ? OS 마다 페이지 캐시 방법이 다를텐데 OS 에 따라 성능이 달라질 수 있는걸까 ?

## 데이터 복제, 싱크
- 복제의 이유 : 클러스터 내 브로커 중 일부 장애가 발생하더라도 데이터 유실 없이 대응 가능
- 카프카의 데이터 복제는 파티션 단위
- 토픽을 생성할 때 파티션의 복제 개수도 같이 설정됨
- 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라감 (최소 1 최대: 브로커 개수)
- 리더 : 실제 데이터 들은 곳, 프로듀셔 또는 컨슈머와 직접 통신하는 파티션
- 팔로워 : 복제 데이터 가지고 있는 파티션
- 복제 과정 : 팔로워 파티션들은 리더 파티션의 오프셋을 확인해서 현재 자신이 가지고 있는 오프셋과 차이나는 경우 리더 파티션으로부터 데이터 가져와서 자신의 파티션에 저장함
- 운영 시에는 데이터 종류마다 다른 복제 개수를 설정하고 토픽마다도 다른 복제 개수를 설정할 수 있음
- 데이터 유실되어도 괜찬 ? 처리 속도 중요 = 1,2 ..
- 유실 x : 3이상 

| ES   | 카프카 |     |
|------|-----|-----|
| 노드   | 브로커 |     |
| 샤드   | 파티션 |     |
| 마스터  | 리터  |     |
| 레플리카 | 팔로워 |     |
| 인덱스  | 토픽  |     |


## 컨트롤러
- 브로커 중 한 대가 컨트롤러 역할
- 브로커들의 상태를 체크하고 리더 파티션을 재분배 함
- 지속적으로 데이터를 처리해야 하므로 브로커의 상태가 비정상적이라면 빠르게 클러스터를 빼내는게 좋음

## 데이터 삭제
> 1GB 가 쌓이는 동안 세그먼트 오픈 -> 닫힘 -> 이후 log.retention.* 이 지난 시점에서 데이터 삭제됨

> ? 데이터가 한 번도 안가져가져도 삭제되나 ?!?!

- 컨슈머가 데이터를 가져가더라도 데이터를 삭제하지는 않음
- 오직 브로커만이 데이터를 삭제
- 데이터 삭제는 파일 단위로 이루어짐 - 로그 세그먼트
- 세그먼트는 데이터가 쌓이는 동안 파일 시스템에 열려있음 log.segment.bytes, ms(기본 값 1GB) 옵션에 값이 설정되면 세그먼트 파일이 닫힘
- 해당 값을 너무 작게 설정해두면 세그먼트 파일 너무 자주 여닫음 -> 부하
- 닫힌 세그먼트 파일은 log.retention.bytes, ms 옵션 값을 넘으면 삭제됨
- 닫힌 세그먼트 파일을 체크하는 간격 : log.retention.check.interval.ms 

## 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋
- _consumer_offsets

## 코디네이터
- 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할 (리밸런스)


## 주키퍼의 역할
- 카프카의 메타 데이터를 관리하는데 사용
- 분산 애플리케이션 사용 시 분산 애플리케이션 관리를 위해 안정적인 코디네이터 애플리케이션이 필요하
- 주키퍼 :
  - 분산 애플리케이션 코디네이션 시스템 
  - 분산 되어 있는 매플리케이션 정보 중앙 집중 구성 관리 네이밍 동기화함
- 카프카 클러스터로 묶인 브로커들은 동일한 경로의 주키퍼 경로로 설ㄴ언해야 같은 카프카 브로커 묶음이 됨


## 토픽과 파티션
- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위 
- 1개 이상의 파티션을 소유하고 있음
- 파티션은 카프카의 병렬 처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리 할 수 있도록 매칭된다 
- 일반적인 자료구조와는 달리 카프카는 데이터를 삭제하지 ㅇ낳음 
- 파티션의 레코드는 컨슈머가 가져가는 것과 별도로 관리됨
- 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 가져갈 수 있다
> ? 컨슈머의 처리량이 한정된 상태에서 많은 레코드를 병렬로 처리하는 가장 좋은 바업은 컨슈머의 개수를 늘려 스케일아웃 하는 것이다.
> ? 파티션이랑 컨슈머를 매칭하는 개념이 이해가 안감 


### 토픽 이름
- 대소문자 구분함, . , _ 연속 불가
- 토픽 이름 변경 안됨
- 처음부터 룰을 만들어서 규칙을 잘 따르자 !


## 레코드 
- 타임프탬프, 메시지 키, 메시지 값, 오프셋, 헤더
- 브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제됨 
### 타임스탬프
- 해당 레코드가 생성된 시점의 유닉스 타임이지만, 프로슈서가 변경가능하고 브로커에 따라 브로커 적재 시간일 수 있음
### 메시지 키 
- 어떤 파티션에 저장할지 결정, 동일한 메시지키라면 동일 파티션에 저장됨 
- 파티션 개수 달라지면 매칭이 달라짐
- 메시지키 null 일 경우 프로듀서 기본 설정 파티셔너에 따라 분배됨
- 직렬화되어 브로커 전달

### 메시지 값
- 실질적 처리 데이터
- 직렬화되어 브로커로 전달
- 컨슈머가 동일한 직렬화 방법으로 역직렬화 해야 함

### 오프센
- 0 이상의 숫자
- 레코드의 오프셋은 직접 지정할 수 없고 브로커에 저장될 때 이전에 전송된 레코드의 오프센 + 1 값으로 생성
- 컨슈머가 데이터를 가져갈 때 사용됨


## 카프카 클라이언트
> 카프카 클러스터에 명령을 내리거나 데이터를 송수신하기 위해 카프카 클라이언트 라이브러리는 카프카 프로듀서 컨슈머 어드민 클라이언트를 제공



### 프로듀서 API
- 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송한다.
- 프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신함
- 