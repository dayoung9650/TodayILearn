# 카프카 상세 개념 설명
## 토픽과 파티션
> 토픽은 카프카의 시작과 끝이다
> 카프카를 사용하는 것은 토픽을 만들면서 시작됨
> 토픽에 대해 잘 이해하고 설정을 잘하는 것이 카프카 데이터 활용도 높임
### 적정 파티션 개수
> 토픽의 파티션 개수는 카프카의 성능과 관련이 있음
1. 데이터 처리량
2. 메시지 키 사용 여부
3. 브로커, 컨슈머 영향도

- 파티션 = 카프카 병렬 처리의 핵심
- 파티션 개수가 많아질수록 1:1 매핑되는 컨슈머 개수가 늘어나기 떄문
- 파티션 개수를 정할 때는 토픽에 필요한 데이터 처리량을 측정하여 정하는 것이 중요

### 데이터 처리 속도를 올리는 방법 
1. 컨슈머의 처리량을 늘림
   - 컨슈머 서버의 스케일 업, GC 튜닝
   - 일정 수준 이상의 처리량 올리기 어려움, 대부분 컨슈머 특성 상 다른 시스템과 연동되기 때문
2. 컨슈머를 추가해서 병렬처리량을 늘림
   - 데이터 처리량을 늘리는 가장 확실한 방법
   - 프로듀서가 보내는 데이터 양과 컨슈머의 데이터 처리량을 계산해서 파티션 개수를 정하면 됨
   - 프로듀서 전송 데이터량 < 컨슈머 데이터 처리량 X 파티션 개수
   - 전체 컨슈머 처리량이 프로듀서 처리량보다 적다면 컨슈머 랙 발생, 데이터 처리 지연
   - 컨슈머 데이터 처리량을 구함
     - 다른 시스템과 연동되는 카프카의 특성에 따라 상용환경에서의 테스트를 권장함
   - 프로듀서가 보내는 데이터양을 하루, 시간, 분 단위로 쪼개서 예측함
     - 데이터의 지연이 절대로 발생하며 안된다면 프로듀서가 보내는 데이터의 최대치를 데이터 생성량으로 잡고 계산
     - 데이터 지연 발생하도 된다면 프로듀서가 보내는 데이터의 최대치를 잡지 않아도 됨
   - 파티션 개수를 무조건 늘리는게 능사는 아님
   - 파티션 개수 늘리면 컨슈머, 브로커에도 부담이 있음
3. 메시지 키 사용 여부 결정
   - 메시지 키를 사용 = 데이터 처리 순서를 지켜야 하는 경우 고려 필요
     - 메시지 키를 해시 변환하여 메세지 키를 파티션에 매칭시킴
     - 파티션의 개수가 달라지면 메시지 키에 따라 저장되는 파티션이 바뀔 수 있음
     - 파티션 개수가 달라지는 순간에는 메시지 키를 사용하는 컨슈머는 특정 메시지 키의 순서를 보장받지 못함

4. 브로커와 컨슈머의 영향도
   - 카프카는 파일 시스템을 사용하기 때문에 파티션이 늘어나는 만큼 브로커에서 접근하는 파일 개수가 많아짐
   - 파티션이 늘어나는 만큼 브로커에서 접근하는 파일 개수가 많아짐
   - open files 최대 개수 정해져 있음
   - 브로커 당 파티션 개수를 모니터링 해야 함
   - 데이터 양이 많아져서 파티션 개수를 늘려야 하는 상황이라면 브로커 당 파티션 개수를 확인하고 진행해야 함
   - 브로커당 파티션 개수가 너무 많다면 카프카 브로커 개수를 늘리는 방안 고려

### 토픽 관리 정책
- 데이터를 더는 사용하지 않을 경우 cleanup.policy 옵션을 사용하여 데이터 삭제
- cleanup.policy 옵션
  - delete : 데이터 완전 삭제 
    - 세그먼트 단위로 데이터를 삭제
    - 세그먼트는 파티션마다 별개로 생성되며 세그먼트 파일 이름은 오프셋 중 가장 작은 값
    - segment.bytes 옵션으로 1개 세그먼트 크기를 설정
    - retention.ms : 토픽의 데이터를 유지하는 기간
    - retention.bytes : 토픽의 최대 데이터 크기를 제어
    - 카프카는 일정 주기마다 세그먼트 파일의 마지막 수정 시간과 retention.ms 를 비교함, 마지막 수정 시간이 retention.ms 를 지나면 세그먼트 삭제됨
  - compact : 동일 메시지 키의 가장 오래된 데이터 삭제
    - 여기서 압축이란 메시지 키별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책
    - 1개 파티션에서 오프셋의 증가가 일정하지 않을 수 있음
    - 메시지 키를 기반으로 데이터 처리할 경우 유용
    - 액티브 세그먼트를 제외한 나머지 세그먼트들에 한해서만 데이터를 처리함
    - min.cleanable.dirty.ratio : 액티브 세그먼트를 제외한 세그먼트에 남아있는 데이터의 테일 영역의 레코드 개수와 헤드 영역의 레코드 개수 비율
      - 테일 : 클린 로그, 압축이 완료된 데이터, 중복 메시지 키 없음
      - 헤드 : 더티 로그, 압축되기 전 레코드들, 중복 메시지 키 
      - 토픽 별로 데이터의 특성에 맞는 적절한 설정 값 필요
### ISR (In Sync Replicas)
> 리더파티션과 팔로워 파티션이 모두 싱크가 된 상태
- 리더 파티션의 데이터가 (오프셋) 팔로워 파티션의 데이터와 완전히 동기화된 상태
- 데이터를 복제하는데 시간이 걸림
- 프로듀서가 특정 파티션에 데이터를 저장하는 작업은 리더 파티션을 통해 처리함
- 시간차 발생
- 리더 파티션은 복제 잘 하고 있는지 확인함
- replica.lag.time.max.ms 주기로 확인
- replica.lag.time.max.ms 보다 긴 시간 동안 데이터를 가져가지 않는다면 해당 팔로워 파티션에 문제가 생긴 것으로 판단하고 ISR 그룹에서 제외함
- ISR = 리더 자격 있음 ! 

### 리더 자격 줄까 말까 ?
> 토픽 별로 설정 가능 
> --config unclean.leader.election.enable=true
- uncleean.leader.election = true / ISR 아니더라도 리더 해라 ! 
  - 데이터 유실 가능성
  - 서비스가 중단 X
- uncleean.leader.election = false / ISR 아니면 리더 안돼 !!
  - 데이터 유실 X
  - 서비스 중단

## 카프카 프로듀서

### Acks 옵션
> acks 옵션 0, 1, all 프로듀서가 전송한 데이터가 카프카 클러스터에 얼마나 신뢰성 높게 저장 ? 
> 추천 ! :
> 토픽의 복제 개수 3 / min.insync.replicas 2 / acks = all
#### acks = 0 
- 아예 확인 안함 
- 당연히 저장 되었겠지~ 
- 데이터 유실 가능
- 빠름
- 재시도 불가능
- 몇 번째 오프셋에 저장되었는지 확인 불거
#### acks 
- 리더 파티션에만 확인
- 재시도 가능 
- 리더 파티션이 있는 브로커에 장애 나면 동기화되지 못한 일부 데이터 유실 가능성
- 속도 느림

#### acks == all (-1)
- 리더파티션, 팔로워 파티션 다 확인
- 속도느림
- 안전
- min.insync.replicas 옵션값에 따라 안정성이 달라짐
  - 모든 파티션 확인이 아닌 ISR 에 포함된 파티션들을 뜻함
  - 최소 ISR 그룹의 파티션 개수
- acks = all , min.insync.replicas = 1 과 acks = 1 은 동일함
- min.insync.replicas 2 부터는 팔로워 파티션도 확인하므로 데이터 유실되지 않는다고 볼 수 있음

> min.insync.replica
> 카프카 브로커 개수보다 무조건 작아야 함 같으면 안됨
> 브로커 하나가 장애 났을 경우, 해당 옵션 값이 브로커 개수와 같다면 장애난 브로커 때문에 복제가 안됨

### 멱등성 프로듀서
> 여러번 연산을 수행하더라도 동일한 결과를 나타냄
- 동일한 데이터 여러 번 전송하더라도 카프카 클러스터에 단 한 번만 저장됨
- 기본 프로듀서 = at least once delivery 
  - 데이터가 유실되지 않음
  - 중복이 발생할 수 있음
- enable.idempotence 기본값 : false 

#### 멱등성 프로듀서 사용 방법
> enable.idempotence : true
- pId, 시퀀스 넘버 함께 브로커로 보냄
- 브로커는 해당 값을 키 값으로 동일한 적재 요청 오더라도 한 번만 데이터 저장함
- 프로듀서가 장애 나서 pId 가 바뀌는 경우는 다른 애플리케이션이라고 판단하고 중복 저장함
- 일부 옵션 강제 설정됨
  - 데이터 재전송 횟수를 정하는 retries 는 Integer.MAX_VALUE
  - acks : all
- 시퀀스 넘버 다르게 오는 경우 : OutOfOrderSequenceException 

### 트랜잭션 프로듀서
- 다수의 파티션에 데이터 저장할 경우 모든 데이터에 대해 동일한 원자성 만족시킴
- 다수의 데이터를 동일한 트랜잭션으로 묶음으로써 전체 데이터 처리하거나 처리하지 ㅇ낳음
- COMMIT 레코드를 하나 더 보냄 오프셋 하나 차지
- 컨슈머는 커밋이 롼료된 데이터가 파티션에 있을 경우에만 데이터를 가져감

## 카프카 컨슈머

### 멀티 스레드 컨슈머
- 처리량을 늘리기 위해 컨슈머 개수를 늘릴 수 있지만 하나의 컨슈머에서 스레드를 늘릴 수 있음
- 파티션 개수가 n 이라면 동일 컨슈머 그룹으로 묶인 컨슈머 스레드를 최대 n개 운영 가능
- 단점 : 
  - 예외적 상황이 발생할 경우 다른 컨슈머 스레드까지 영향줄 수 있음
  - 스레드 세이프 로직 변수 적용ㅎ야 함
#### 멀티 워커 스레드 전략
> 컨슈머 스레드는 1개만 실행하고 데이터 처리를 담당하는 워커 스레드를 여러개 실행
- poll() 은 컨슈머 스레드 1개에서 수행, 이후 레코드들 가져와서 수행하는 작업을 병렬 실행
- 데이터 처리가 끝나지 않았는데 커밋하기 때문에 리밸런싱, 컨슈머 장애 시에 데이터 유실 발생 가능성
- 레코드의 순서가 뒤바뀔 수 있음
- 중복 역전 발생해도 되고 빠른 처리 속도가 필요한 데이터 처리

#### 카프카 컨슈머 멀티 스레드 전략
> 컨슈머 인스턴스에서 poll() 메소드를 호출하는 스레드를 여러 개 띄워서 사용

### 컨슈머 랙
- 토픽의 최신 오프셋과 컨슈머 오프셋 간의 차이
- 프로듀서가 생성하는 데이터를 컨슈머의 처리량이 따라가지 못할 떄 발생하는 상황
- 

